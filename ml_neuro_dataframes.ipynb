{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b655e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import functions\n",
    "importlib.reload(functions)\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f1ac2b",
   "metadata": {},
   "source": [
    "# Building Dataframes to Make Calculations\n",
    "\n",
    "I found throughout my coding of this project that creating parcellation vectors of each image took a lot of time and the run time for all the brain files can take anywhere from 3-12 hours (yikes!). I realized dataframes made it much easier to view and store this information as well as cut down run time, so that every time I run the program I am not spending 3-12 hours just to load all the vectors. \n",
    "\n",
    "To have my data be easily for myself if I return to this project or for others who want to run the code themselves, I decided to save each of the dataframes as csv files. Storing all the data in a csv file that I can read instantly into a pandas dataframe saves me and anyone else who wants to run the following code tons of time. None the less I included below the code I used to create the pandas dataframes to show my work and each step of my calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434f6fa",
   "metadata": {},
   "source": [
    "## Raw DataFrame\n",
    "\n",
    "This data frame consists of all the files in the dataset (270 beta-map images), their respective emotion states and priming conditions as well as vectors corresponding to each parcellation atlas. Explanation for the columns are as follows:\n",
    "\n",
    "* `filename`: Name of the fMRI brain image file\n",
    "* `emotion`: Emotion of the image shown to the subject\n",
    "* `priming`: Priming condition of the subject before shown an image\n",
    "\n",
    "\n",
    "\n",
    "* `aal_spm12`: AAL template for SPM 12.This atlas is the result of an automated anatomical parcellation of the spatially normalized single-subject high-resolution T1 volume provided by the Montreal Neurological Institute (MNI) (D. L. Collins et al., 1998, Trans. Med. Imag. 17, 463-468, PubMed)   \n",
    "\n",
    "\n",
    "\n",
    "* `allen_28`: T-maps of 28 RSNs from Allen and MIALAB ICA atlas (dated 2011)\n",
    "* `allen_75`: T-maps of all 75 unthresholded components from Allen and MIALAB ICA atlas (dated 2011)\n",
    "\n",
    "\n",
    "\n",
    "* `difumo_64_2`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 64 and resolution mm of 2. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "* `difumo_64_3`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 64 and resolution mm of 3. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "\n",
    "\n",
    "\n",
    "* `difumo_128_2`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 128 and resolution mm of 2. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "* `difumo_128_3`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 128 and resolution mm of 3. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "\n",
    "\n",
    "\n",
    "* `difumo_256_2`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 256 and resolution mm of 2. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "* `difumo_256_3`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 256 and resolution mm of 3. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "\n",
    "\n",
    "\n",
    "* `difumo_512_2`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 512 and resolution mm of 2. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "* `difumo_512_3`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 512 and resolution mm of 3. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "\n",
    "\n",
    "\n",
    "* `difumo_1024_2`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 1024 and resolution mm of 2. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "* `difumo_1024_3`: Atlas from Dictionaries of Functional Modes, or “DiFuMo”, that extracts functional signals with a dimensionality of 1024 and resolution of 3. These modes are optimized to represent well raw BOLD timeseries, over a with range of experimental conditions.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cort_0_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 0 and resolution mm of 1.\n",
    "* `harvard_oxford_cort_0_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 0 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cort_25_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 25 and resolution mm of 1.\n",
    "* `harvard_oxford_cort_25_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 25 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cort_50_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 50 and resolution mm of 1.\n",
    "* `harvard_oxford_cort_50_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 50 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cort_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with resolution mm of 1.\n",
    "* `harvard_oxford_cort_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cortl_0_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 0 and resolution mm of 1.\n",
    "* `harvard_oxford_cortl_0_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 0 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cortl_25_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 25 and resolution mm of 1.\n",
    "* `harvard_oxford_cortl_25_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 25 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cortl_50_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 50 and resolution mm of 1.\n",
    "* `harvard_oxford_cortl_50_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 50 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_cortl_1`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with resolution mm of 1.\n",
    "* `harvard_oxford_cortl_2`: Probabilistic atlas covering cortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_sub_0_1`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 0 and resolution mm of 1.\n",
    "* `harvard_oxford_sub_0_2`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 0 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_sub_25_1`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 25 and resolution mm of 1.\n",
    "* `harvard_oxford_sub_25_2`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 25 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_sub_50_1`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 50 and resolution mm of 1.\n",
    "* `harvard_oxford_sub_50_2`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with threshold of 50 and resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `harvard_oxford_sub_1`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with resolution mm of 1.\n",
    "* `harvard_oxford_sub_2`: Probabilistic atlas covering subcortical structural areas derived from structural data and segmentations by the Harvard Center for Morphometric Analysis with resolution mm of 2.\n",
    "\n",
    "\n",
    "\n",
    "* `icbm_cerebrospinal`: Cerebrospinal fluid segmented image from ICBM152 template (dated 2009)\n",
    "* `icbm_eye_mask`: Eye mask useful to mask out part of MRI images from ICBM152 template (dated 2009)\n",
    "* `icbm_face_mask`: Face mask useful to mask out part of MRI images from ICBM152 template (dated 2009)\n",
    "* `icbm_grey_matter`: Grey matter segmented image from ICBM152 template (dated 2009)\n",
    "* `icbm_p_density`: Proton density weighted anatomical image from ICBM152 template (dated 2009)\n",
    "* `icbm_skull_mask`: Whole brain mask useful to mask out skull areas from ICBM152 template (dated 2009)\n",
    "* `icbm_t1_weighted`: T1-weighted anatomical image from ICBM152 template (dated 2009)\n",
    "* `icbm_t2_relaxometry`: Anatomical image obtained with the T2 relaxometry from ICBM152 template (dated 2009)\n",
    "* `icbm_t2_weighted`: T2-weighted anatomical image from ICBM152 template (dated 2009)\n",
    "* `icbm_white_matter`: White matter segmented image from ICBM152 template (dated 2009)\n",
    "* `icbm_wm_gm_csf`: Combination of white matter, grey matter and cerebrospinal fluid segmented images from ICBM152 template (dated 2009)\n",
    "\n",
    "\n",
    "\n",
    "* `juelich_0_1`: Juelich parcellations from FSL with threshold of 0 and resolution mm of 1.\n",
    "* `juelich_0_2`: Juelich parcellations from FSL with threshold of 0 and resolution mm of 2.\n",
    "* `juelich_1`: Juelich parcellations from FSL with resolution mm of 1.\n",
    "* `juelich_2`: Juelich parcellations from FSL with resolution mm of 2.\n",
    "* `juelich_25_1`: Juelich parcellations from FSL with threshold of 25 and resolution mm of 1.\n",
    "* `juelich_25_2`: Juelich parcellations from FSL with threshold of 25 and resolution mm of 2.\n",
    "* `juelich_50_1`: Juelich parcellations from FSL with threshold of 50 and resolution mm of 1.\n",
    "* `juelich_50_2`: Juelich parcellations from FSL with threshold of 50 and resolution mm of 2.\n",
    "\n",
    "\n",
    "* `msdl`: MSDL brain atlas\n",
    "* `pauli_subcortex_det`: Pauli (2017) probabilistic atlas with in total 12 subcortical nodes\n",
    "* `pauli_subcortex_prob`: Pauli (2017) deterministic atlas with in total 12 subcortical nodes\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_100_17_1`: Schaefer 2018 parcellation of 100 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_100_17_2`: Schaefer 2018 parcellation of 100 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_100_7_1`: Schaefer 2018 parcellation of 100 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_100_7_2`: Schaefer 2018 parcellation of 100 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_200_17_1`: Schaefer 2018 parcellation of 200 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_200_17_2`: Schaefer 2018 parcellation of 200 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_200_7_1`: Schaefer 2018 parcellation of 200 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_200_7_2`: Schaefer 2018 parcellation of 200 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_300_17_1`: Schaefer 2018 parcellation of 300 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_300_17_2`: Schaefer 2018 parcellation of 300 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_300_7_1`: Schaefer 2018 parcellation of 300 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_300_7_2`: Schaefer 2018 parcellation of 300 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_400_17_1`: Schaefer 2018 parcellation of 400 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_400_17_2`: Schaefer 2018 parcellation of 400 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_400_7_1`: Schaefer 2018 parcellation of 400 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_400_7_2`: Schaefer 2018 parcellation of 400 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_500_17_1`: Schaefer 2018 parcellation of 500 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_500_17_2`: Schaefer 2018 parcellation of 500 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_500_7_1`: Schaefer 2018 parcellation of 500 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_500_7_2`: Schaefer 2018 parcellation of 4500 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_600_17_1`: Schaefer 2018 parcellation of 600 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_600_17_2`: Schaefer 2018 parcellation of 600 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_600_7_1`: Schaefer 2018 parcellation of 600 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_600_7_2`:Schaefer 2018 parcellation of 600 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_700_17_1`: Schaefer 2018 parcellation of 700 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_700_17_2`: Schaefer 2018 parcellation of 700 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_700_7_1`: Schaefer 2018 parcellation of 700 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_700_7_2`: Schaefer 2018 parcellation of 700 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_800_17_1`: Schaefer 2018 parcellation of 800 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_800_17_2`: Schaefer 2018 parcellation of 800 regions of interests, 17 yeo networks\n",
    "* `schaefer_800_7_1`: Schaefer 2018 parcellation of 800 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_800_7_2`: Schaefer 2018 parcellation of 800 regions of interests, 7 yeo networks\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_900_17_1`: Schaefer 2018 parcellation of 900 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_900_17_2`: Schaefer 2018 parcellation of 900 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_900_7_1`: Schaefer 2018 parcellation of 900 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_900_7_2`: Schaefer 2018 parcellation of 900 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `schaefer_1000_17_1`: Schaefer 2018 parcellation of 1000 regions of interests, 17 yeo networks and resolution mm of 1\n",
    "* `schaefer_1000_17_2`: Schaefer 2018 parcellation of 1000 regions of interests, 17 yeo networks and resolution mm of 2\n",
    "* `schaefer_1000_7_1`: Schaefer 2018 parcellation of 1000 regions of interests, 7 yeo networks and resolution mm of 1\n",
    "* `schaefer_1000_7_2`: Schaefer 2018 parcellation of 1000 regions of interests, 7 yeo networks and resolution mm of 2\n",
    "\n",
    "\n",
    "\n",
    "* `smith_10_brainmap`: Smith BrainMap atlas (dated 2009) 10-dimensional ICA, BrainMap components\n",
    "* `smith_20_brainmap`: Smith BrainMap atlas (dated 2009) 20-dimensional ICA, BrainMap components\n",
    "* `smith_70_brainmap`: Smith BrainMap atlas (dated 2009) 70-dimensional ICA, BrainMap components\n",
    "\n",
    "\n",
    "\n",
    "* `smith_10_rsn`: Smith ICA atlas (dated 2009) 10-dimensional ICA, Resting-FMRI components\n",
    "* `smith_20_rsn`: Smith ICA atlas (dated 2009) 20-dimensional ICA, Resting-FMRI components\n",
    "* `smith_70_rsn`: Smith ICA atlas (dated 2009) 70-dimensional ICA, Resting-FMRI components\n",
    "\n",
    "\n",
    "\n",
    "* `talairach_ba`: Talairach atlas of Brodman area level\n",
    "* `talairach_gyrus`: Talairach atlas of gyrus level\n",
    "* `talairach_hemi`: Talairach atlas of hemisphere level\n",
    "* `talairach_lobe`: Talairach atlas of lobe level\n",
    "* `talairach_tissue`: Talairach atlas of tissue type level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082105d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandafrancis/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py:2407: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n",
      "/Users/anandafrancis/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/npyio.py:2407: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  output = genfromtxt(fname, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create variables to represent all subjects, emotion states and priming conditions\n",
    "subs = list(range(1, 31))\n",
    "emotions = ['anger', 'disgust','fear']\n",
    "primings = ['congruent', 'incongruent', 'neutral']\n",
    "\n",
    "# create list of all the brain image files\n",
    "dataset = create_file_list(subs, emotions, primings)\n",
    "\n",
    "# create dataframe of all the raw data\n",
    "data_df = pd.DataFrame({'filename': dataset})\n",
    "data_df['emotion'] = data_df.apply(lambda row: get_class(row.filename), axis = 1)\n",
    "data_df['priming'] = data_df.apply(lambda row: get_priming(row.filename), axis = 1)\n",
    "\n",
    "# create dict and list of all parcellation atlases\n",
    "atlas_types = parcellation_atlas_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7622ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each parcellation technique create column of vectors\n",
    "data_df['aal_spm12'] = parcellized_brain_vecs(dataset, atlas_types, 'AAL SPM12')\n",
    "data_df['allen_28'] = parcellized_brain_vecs(dataset, atlas_types, 'Allen 28')\n",
    "data_df['allen_75'] = parcellized_brain_vecs(dataset, atlas_types, 'Allen 75')\n",
    "\n",
    "data_df['difumo_64_2'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 64 x 2')\n",
    "data_df['difumo_64_3'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 64 x 3')\n",
    "data_df['difumo_128_2'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 128 x 2')\n",
    "data_df['difumo_128_3'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 128 x 3')\n",
    "data_df['difumo_256_2'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 256 x 2')\n",
    "data_df['difumo_256_3'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 256 x 3')\n",
    "data_df['difumo_512_2'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 512 x 2')\n",
    "data_df['difumo_512_3'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 512 x 3')\n",
    "data_df['difumo_1024_2'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 1024 x 2')\n",
    "data_df['difumo_1024_3'] = parcellized_brain_vecs(dataset, atlas_types, 'DiFuMo 1024 x 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c10a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['harvard_oxford_cort_0_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 0 x 1')\n",
    "data_df['harvard_oxford_cort_0_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 0 x 2')\n",
    "data_df['harvard_oxford_cort_25_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 25 x 1')\n",
    "data_df['harvard_oxford_cort_25_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 25 x 2')\n",
    "data_df['harvard_oxford_cort_50_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 50 x 1')\n",
    "data_df['harvard_oxford_cort_50_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 50 x 2')\n",
    "data_df['harvard_oxford_cort_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 1')\n",
    "data_df['harvard_oxford_cort_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cort 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['harvard_oxford_cortl_0_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 0 x 1')\n",
    "data_df['harvard_oxford_cortl_0_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 0 x 2')\n",
    "data_df['harvard_oxford_cortl_25_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 25 x 1')\n",
    "data_df['harvard_oxford_cortl_25_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 25 x 2')\n",
    "data_df['harvard_oxford_cortl_50_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 50 x 1')\n",
    "data_df['harvard_oxford_cortl_50_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 50 x 2')\n",
    "data_df['harvard_oxford_cortl_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 1')\n",
    "data_df['harvard_oxford_cortl_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford cortl 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['harvard_oxford_sub_0_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 0 x 1')\n",
    "data_df['harvard_oxford_sub_0_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 0 x 2')\n",
    "data_df['harvard_oxford_sub_25_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 25 x 1')\n",
    "data_df['harvard_oxford_sub_25_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 25 x 2')\n",
    "data_df['harvard_oxford_sub_50_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 50 x 1')\n",
    "data_df['harvard_oxford_sub_50_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 50 x 2')\n",
    "data_df['harvard_oxford_sub_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 1')\n",
    "data_df['harvard_oxford_sub_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Harvard_Oxford sub 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['icbm_eye_mask'] = parcellized_brain_vecs(dataset, atlas_types, 'ICBM Eye Mask')\n",
    "data_df['icbm_face_mask']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM Face Mask')\n",
    "data_df['icbm_skull_mask']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM Skull Mask')\n",
    "data_df['icbm_grey_matter']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM Grey Matter')\n",
    "data_df['icbm_white_matter']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM White Matter')\n",
    "data_df['icbm_cerebrospinal']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM Cerebrospinal')\n",
    "data_df['icbm_wm_gm_csf'] = parcellized_brain_vecs(dataset, atlas_types, 'ICBM WM x GM x CSF')\n",
    "data_df['icbm_t1_weighted'] = parcellized_brain_vecs(dataset, atlas_types, 'ICBM T1-Weighted')\n",
    "data_df['icbm_t2_weighted'] = parcellized_brain_vecs(dataset, atlas_types, 'ICBM T2-Weighted')\n",
    "data_df['icbm_t2_relaxometry']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM T-2 Relaxometry')\n",
    "data_df['icbm_p_density']= parcellized_brain_vecs(dataset, atlas_types, 'ICBM Proton Density Weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac760091",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['juelich_0_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 0 x 1')\n",
    "data_df['juelich_0_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 0 x 2')\n",
    "data_df['juelich_25_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 25 x 1')\n",
    "data_df['juelich_25_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 25 x 2')\n",
    "data_df['juelich_50_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 50 x 1')\n",
    "data_df['juelich_50_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 50 x 2')\n",
    "data_df['juelich_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 1')\n",
    "data_df['juelich_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Juelich 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['msdl'] = parcellized_brain_vecs(dataset, atlas_types, 'MSDL')\n",
    "\n",
    "data_df['pauli_subcortex_det'] = parcellized_brain_vecs(dataset, atlas_types, 'Pauli Subcortex Det')\n",
    "data_df['pauli_subcortex_prob'] = parcellized_brain_vecs(dataset, atlas_types, 'Pauli Subcortex Prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be54e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_100_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 100 x 7 x 1')\n",
    "data_df['schaefer_100_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 100 x 7 x 2')\n",
    "data_df['schaefer_100_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 100 x 17 x 1')\n",
    "data_df['schaefer_100_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 100 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896e1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_200_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 200 x 7 x 1')\n",
    "data_df['schaefer_200_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 200 x 7 x 2')\n",
    "data_df['schaefer_200_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 200 x 17 x 1')\n",
    "data_df['schaefer_200_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 200 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e5090",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_300_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 300 x 7 x 1')\n",
    "data_df['schaefer_300_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 300 x 7 x 2')\n",
    "data_df['schaefer_300_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 300 x 17 x 1')\n",
    "data_df['schaefer_300_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 300 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be842f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_400_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 400 x 7 x 1')\n",
    "data_df['schaefer_400_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 400 x 7 x 2')\n",
    "data_df['schaefer_400_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 400 x 17 x 1')\n",
    "data_df['schaefer_400_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 400 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fd9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_500_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 500 x 7 x 1')\n",
    "data_df['schaefer_500_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 500 x 7 x 2')\n",
    "data_df['schaefer_500_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 500 x 17 x 1')\n",
    "data_df['schaefer_500_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 500 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_600_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 600 x 7 x 1')\n",
    "data_df['schaefer_600_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 600 x 7 x 2')\n",
    "data_df['schaefer_600_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 600 x 17 x 1')\n",
    "data_df['schaefer_600_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 600 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96631e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_700_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 700 x 7 x 1')\n",
    "data_df['schaefer_700_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 700 x 7 x 2')\n",
    "data_df['schaefer_700_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 700 x 17 x 1')\n",
    "data_df['schaefer_700_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 700 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e32a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_800_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 800 x 7 x 1')\n",
    "data_df['schaefer_800_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 800 x 7 x 2')\n",
    "data_df['schaefer_800_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 800 x 17 x 1')\n",
    "data_df['schaefer_800_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 800 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c92fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_900_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 900 x 7 x 1')\n",
    "data_df['schaefer_900_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 900 x 7 x 2')\n",
    "data_df['schaefer_900_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 900 x 17 x 1')\n",
    "data_df['schaefer_900_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 900 x 17 x 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152d6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['schaefer_1000_7_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 1000 x 7 x 1')\n",
    "data_df['schaefer_1000_7_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 1000 x 7 x 2')\n",
    "data_df['schaefer_1000_17_1'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 1000 x 17 x 1')\n",
    "data_df['schaefer_1000_17_2'] = parcellized_brain_vecs(dataset, atlas_types, 'Schaefer 1000 x 17 x 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54fcbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['smith_10_rsn'] = parcellized_brain_vecs(dataset, atlas_types, 'Smith 10 RSNs')\n",
    "data_df['smith_20_rsn'] = parcellized_brain_vecs(dataset, atlas_types, 'Smith 20 RSNs')\n",
    "data_df['smith_70_rsn'] = parcellized_brain_vecs(dataset, atlas_types, 'Smith 70 RSNs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562adb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['smith_10_brainmap'] = parcellized_brain_vecs(dataset, atlas_types, 'Smith 10 Brainmap')\n",
    "data_df['smith_20_brainmap'] = parcellized_brain_vecs(dataset, atlas_types, 'Smith 20 Brainmap')\n",
    "data_df['smith_70_brainmap'] = parcellized_brain_vecs(dataset, atlas_types, 'Smith 70 Brainmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a11525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['talairach_ba'] = parcellized_brain_vecs(dataset, atlas_types, 'Talairach Ba')\n",
    "data_df['talairach_gyrus'] = parcellized_brain_vecs(dataset, atlas_types, 'Talairach Gyrus')\n",
    "data_df['talairach_hemi'] = parcellized_brain_vecs(dataset, atlas_types, 'Talairach Hemi')\n",
    "data_df['talairach_lobe'] = parcellized_brain_vecs(dataset, atlas_types, 'Talairach Lobe')\n",
    "data_df['talairach_tissue'] = parcellized_brain_vecs(dataset, atlas_types, 'Talairach Tissue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a084102",
   "metadata": {},
   "source": [
    "## Standardized DataFrame\n",
    "\n",
    "In order to use classifiers in sklearn library the vectors needs to be standardardized. To make the data compatible as an input I used the train_test_split function in model selection library to turn a column of selected vectors into a normalized 2-D array, making it compatible with the sklearn classifiers. I created train and test arrays for each combination of parcellation and priming condition.\n",
    "\n",
    "Explanations for each column are as follows:\n",
    "\n",
    "* `priming`: Priming condition of the standardized 2-D array\n",
    "* `parcellation`: Parcellation technique that was used to created the vectors of the standardized 2-D array\n",
    "* `X`: Standardized 2-D array composed of list of vectors of the priming condition and parcellation technique of that row\n",
    "* `y`: Corresponding class (emotion state) for each array in `X`\n",
    "* `X_train`: Percentage of arrays from `X` used to train machine learning classifier\n",
    "* `X_test`: Percentage of arrays from `X` used to test machine learning classifier\n",
    "* `y_train`: Corresponding class (emotion state) for each array in `X_train`\n",
    "* `y_test`: Corresponding class (emotion state) for each array in `X_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of testing and training data to run thru sklearn classifiers\n",
    "parcellations = list(df.drop(columns=['filename', 'emotion', 'priming']).columns)\n",
    "\n",
    "algorithms = list(classifier_dict().keys())\n",
    "\n",
    "combos = [(prime, p, algo) for prime in primings for p in parcellations for algo in algorithms]\n",
    "\n",
    "'''these algorithms were removed because there was missing attribute that\n",
    "didn't allow function to run: MultinomialNB','ComplementNB', 'CategoricalNB' '''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "standardized_df = pd.DataFrame()\n",
    "p_n_p = [(prime, p) for prime in primings for p in parcellations]\n",
    "standardized_df['p_&_p'] = p_n_p\n",
    "standardized_df = expand_df(standardized_df, 'p_&_p').rename(columns={'p_&_p_1' : 'priming', 'p_&_p_2': 'parcellation'})\n",
    "\n",
    "standardized_df['X'] = standardized_df.apply(lambda row: standardize(row.priming, row.parcellation, df), axis = 1)\n",
    "standardized_df['y'] = standardized_df.apply(lambda row: list(df[df.priming == row.priming].emotion) , axis = 1)\n",
    "\n",
    "standardized_df['X_train'] = standardized_df.apply(lambda row: train_test_split(row.X, row.y, test_size=0.2)[0], axis=1)\n",
    "standardized_df['X_test'] = standardized_df.apply(lambda row: train_test_split(row.X, row.y, test_size=0.2)[1], axis=1)\n",
    "\n",
    "standardized_df['y_train'] = standardized_df.apply(lambda row: train_test_split(row.X, row.y, test_size=0.2)[2], axis=1)\n",
    "standardized_df['y_test'] = standardized_df.apply(lambda row: train_test_split(row.X, row.y, test_size=0.2)[3], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e517b17",
   "metadata": {},
   "source": [
    "## Testing DataFrame\n",
    "\n",
    "This dataframe is to show metric results of each classifier. For each combination of priming condition, parcellation and classifier I created a dataframe to store the overall f-1 score and accuracy, and the f-1 score and accuracy for each class. \n",
    "\n",
    "* `priming`: Priming condition of data tested \n",
    "* `parcellation`: Parcellation technique that was used to created the vectors of the data tested\n",
    "* `algorithm`: Classifier used to predict class of each data value (vector or Numpy array depending on algorithm)\n",
    "* `predicted`: List of predicted classes for data tested\n",
    "* `actual`: List of actual classes for data tested\n",
    "* `f1`: Overall f-1 score based on class predictions and actual classes\n",
    "* `accuracy`: Overall accuracy score based on class predictions and actual classes\n",
    "* `anger_f1`: f-1 score for anger class\n",
    "* `disgust_f1`: f-1 score for disgust class\n",
    "* `fear_f1`: f-1 score for fear class\n",
    "* `anger_accuracy`: accuracy score for anger class\n",
    "* `disgust_accuracy`: accuracy score for disgust class\n",
    "* `fear_accuracy`: accuracy score for fear class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store classifier results in testing dataframe\n",
    "testing_df = pd.DataFrame()\n",
    "testing_df['combo'] = combos\n",
    "testing_df = expand_df(testing_df, 'combo').rename(columns={'combo_1' : 'priming', 'combo_2': 'parcellation', 'combo_3': 'algorithm'})\n",
    "testing_df['predicted'] = testing_df.apply(lambda row: get_prediction(df, row.priming, row.parcellation, row.algorithm, X_train = get_X_y(standardized_df, row.priming, row.parcellation, 'X_train'), y_train = get_X_y(standardized_df, row.priming, row.parcellation, 'y_train'), X_test = get_X_y(standardized_df, row.priming, row.parcellation, 'X_test')), axis = 1)\n",
    "testing_df['actual'] = testing_df.apply(lambda row: get_actual(df, standardized_df, row.priming, row.parcellation, row.algorithm), axis = 1)\n",
    "\n",
    "testing_df['f1'] = testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'f1'), axis = 1)\n",
    "testing_df['accuracy'] = testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'accuracy'), axis = 1)\n",
    "\n",
    "testing_df['anger_f1'] = testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'anger_f1'), axis = 1)\n",
    "testing_df['disgust_f1'] = testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'disgust_f1'), axis = 1)\n",
    "testing_df['fear_f1'] = testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'fear_f1'), axis = 1)\n",
    "\n",
    "testing_df['anger_accuracy']= testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'anger_accuracy'), axis = 1)\n",
    "testing_df['disgust_accuracy']= testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'disgust_accuracy'), axis = 1)\n",
    "testing_df['fear_accuracy']= testing_df.apply(lambda row: rate_classifier(row.predicted, row.actual, 'fear_accuracy'), axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d39048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all dataframes to csv files to reduce runtime foe those that want to run the code themselves\n",
    "data_df.to_csv('brain_data.csv')\n",
    "standardized_df.to_csv('train_test_data.csv')\n",
    "testing_df.to_csv('testing_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
